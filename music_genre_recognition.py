# -*- coding: utf-8 -*-
"""Music_Genre_Recognition.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1EdltICb8JOa9Np5jUA73W5_TMe5KAXcS
"""

!mdir -p ~/.kaggle
!cp kaggle.json ~/.kaggle/

!kaggle datasets download abdulvahap/music-instrunment-sounds-for-classification

# Commented out IPython magic to ensure Python compatibility.
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
# %matplotlib inline
import librosa
import librosa.display
import IPython.display as ipd
import os
import glob
import random
import tensorflow as tf
import warnings
warnings.filterwarnings('ignore')
import seaborn as sns

import sklearn
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import LabelEncoder, StandardScaler
from tensorflow import keras
from tensorflow.keras import layers
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense, Dropout, Activation, Flatten,MaxPool2D, Conv2D, MaxPooling2D, BatchNormalization
from tensorflow.keras.optimizers import Adam
from tensorflow.keras.callbacks import TensorBoard



import zipfile
zip_ref = zipfile.ZipFile('music-instrunment-sounds-for-classification.zip', 'r')
zip_ref.extractall()
zip_ref.close()

# Flute Sample for how we check wave of sound
filename = '/content/music_dataset/flute/10.wav'
plt.figure(figsize=(9,3))
data,sample_rate=librosa.load(filename)
librosa.display.waveshow(data,sr=sample_rate)
plt.title('Wave Plot')
plt.show()
print(data)
print(sample_rate)

from IPython.display import Audio

Audio(data=data, rate=sample_rate)

def plot_melspectrogram(y, sr):
  spectogram = librosa.feature.melspectrogram(y=data, sr=sample_rate)
  spectogram_db = librosa.power_to_db(spectogram, ref=np.max)
  plt.figure(figsize=(9,3))
  librosa.display.specshow(spectogram_db, sr=sample_rate, x_axis='time', y_axis='mel')
  plt.colorbar(format='%+2.0f dB')
  plt.title('Mel Spectrogram')
  plt.tight_layout()
  plt.show()

print(sorted(os.listdir('/content/music_dataset')))

main_path = '/content/music_dataset'
label = ['Accordion', 'Acoustic_Guitar', 'Banjo', 'Bass_Guitar', 'Clarinet', 'Cymbals', 'Dobro', 'Drum_set', 'Electro_Guitar', 'Floor_Tom', 'Harmonica', 'Harmonium', 'Hi_Hats', 'Horn', 'Keyboard', 'Mandolin', 'Organ', 'Piano', 'Saxophone', 'Shakers', 'Tambourine', 'Trombone', 'Trumpet', 'Ukulele', 'Violin', 'cowbell', 'flute', 'vibraphone']

def extract_features(main_path, label):
  data = []
  labels = []
  for i_class, class_name in enumerate(label):
    path = os.path.join(main_path, class_name)
    print('preprocessing -- ',class_name)
    for file_name in os.listdir(path):
      if file_name.endswith('.wav'):
        file_path = os.path.join(path, file_name)
        audio_data, sample_rate = librosa.load(file_path, sr=None)

        mfccs = librosa.feature.mfcc(y=audio_data, sr=sample_rate, n_mfcc=80)
        mfccs_scaled = np.mean(mfccs.T, axis=0)
        # Reshape for model input
        mfccs_scaled = mfccs_scaled.reshape(80, 1, 1)

        data.append(mfccs_scaled)
        labels.append(i_class)
  return np.array(data), np.array(labels)

data, labels = extract_features(main_path, label)

data.shape

labels.shape

# convert label into one-hot-encoding
from tensorflow.keras.utils import to_categorical
labels = to_categorical(labels, num_classes=len(label))
labels

labels.shape

X,y = data, labels

X_train, X_test, y_train, y_test = train_test_split(data, labels, test_size=0.2, random_state=42)



model = Sequential()
model.add(Conv2D(filters=32, kernel_size=3, padding='same', activation='relu', input_shape=(80, 1, 1), kernel_regularizer=keras.regularizers.l2(0.01)))
model.add(Conv2D(filters=32, kernel_size=(3, 1), activation='relu', padding='same'))
model.add(BatchNormalization())
model.add(MaxPooling2D(pool_size=(2, 1), strides=(2, 1)))

model.add(Conv2D(filters=64, kernel_size=(3, 1), activation='relu', padding='same', kernel_regularizer=keras.regularizers.l2(0.01)))
model.add(BatchNormalization())
model.add(MaxPooling2D(pool_size=(2, 1), strides=(2, 1)))

model.add(Conv2D(filters=128, kernel_size=(3, 1), activation='relu', padding='same', kernel_regularizer=keras.regularizers.l2(0.01)))
model.add(BatchNormalization())
model.add(MaxPooling2D(pool_size=(2, 1), strides=(2, 1)))

model.add(Conv2D(filters=256, kernel_size=(3, 1), activation='relu', padding='same', kernel_regularizer=keras.regularizers.l2(0.01)))
model.add(BatchNormalization())
model.add(MaxPooling2D(pool_size=(2, 1), strides=(2, 1)))

model.add(Conv2D(filters=512, kernel_size=(3, 1), activation='relu', padding='same', kernel_regularizer=keras.regularizers.l2(0.01)))
model.add(BatchNormalization())
model.add(MaxPooling2D(pool_size=(2, 1), strides=(2, 1)))


model.add(Flatten())
model.add(Dense(units=512, activation='relu', kernel_regularizer=keras.regularizers.l2(0.01)))
model.add(Dropout(0.2))
model.add(Dense(units=256, activation='relu', kernel_regularizer=keras.regularizers.l2(0.01)))
model.add(Dropout(0.2))
model.add(Dense(units=128, activation='relu', kernel_regularizer=keras.regularizers.l2(0.01)))
model.add(Dropout(0.2))
model.add(Dense(units=64, activation='relu', kernel_regularizer=keras.regularizers.l2(0.01)))
model.add(Dropout(0.2))
model.add(Dense(units=32, activation='relu', kernel_regularizer=keras.regularizers.l2(0.01)))
model.add(Dropout(0.2))
model.add(Dense(units=len(label), activation='softmax'))

model.compile(optimizer='adam',loss='categorical_crossentropy',metrics=['accuracy'])
model.summary()

history = model.fit(X_train, y_train, batch_size=32, epochs=10, validation_data=(X_test, y_test))

plt.plot(history.history['accuracy'])
plt.plot(history.history['val_accuracy'])
plt.title('model accuracy')
plt.ylabel('accuracy')
plt.xlabel('epoch')
plt.legend(['train', 'test'], loc='upper left')
plt.show()

plt.plot(history.history['loss'])
plt.plot(history.history['val_loss'])
plt.title('model loss')
plt.ylabel('loss')
plt.xlabel('epoch')
plt.legend(['train', 'test'], loc='upper left')
plt.show()

print('Final training accuracy: ', history.history['accuracy'][-1])
print('Final validation accuracy: ', history.history['val_accuracy'][-1])

def predict_audio(file_path, model, label):
  audio_data, sample_rate = librosa.load(file_path, sr=None)
  mfccs = librosa.feature.mfcc(y=audio_data, sr=sample_rate, n_mfcc=80)
  mfccs_scaled = np.mean(mfccs.T, axis=0)
  mfccs_scaled = mfccs_scaled.reshape(1, 80, 1, 1) # Reshape for model input (add batch dimension)
  prediction = model.predict(mfccs_scaled)
  predicted_class_index = np.argmax(prediction)
  predicted_label = label[predicted_class_index]
  return predicted_label, prediction

# Example usage (assuming 'model' and 'label' are defined from previous code):
file_path = '/content/music_dataset/Organ/1003.wav' # Replace with actual file path
predicted_label, probabilities = predict_audio(file_path, model, label)
print(f"Predicted Label: {predicted_label}")

file_path = '/content/ROOM_room6_MUS_pachelbel_DEV_amazon.wav' # Replace with actual file path
predicted_label, probabilities = predict_audio(file_path, model, label)
print(f"Predicted Label: {predicted_label}")

file_path = '/content/guitar-solo-74247.wav' # Replace with actual file path
predicted_label, probabilities = predict_audio(file_path, model, label)
print(f"Predicted Label: {predicted_label}")

file_path = '/content/Va-ord-F4-ff-2c.wav' # Replace with actual file path
predicted_label, probabilities = predict_audio(file_path, model, label)
print(f"Predicted Label: {predicted_label}")

file_path = '/content/rock-drum-loop-85371.wav' # Replace with actual file path
predicted_label, probabilities = predict_audio(file_path, model, label)
print(f"Predicted Label: {predicted_label}")

file_path = '/content/Sad-Violin-Fast-E-www.fesliyanstudios.com.wav' # Replace with actual file path
predicted_label, probabilities = predict_audio(file_path, model, label)
print(f"Predicted Label: {predicted_label}")



import zipfile
zip_ref = zipfile.ZipFile('/content/Test_submission.zip', 'r')
zip_ref.extractall()
zip_ref.close()

def predict_audio_folder(folder_path, model, label):
  for filename in os.listdir(folder_path):
    if filename.endswith(('.wav', '.mp3')): # Adjust extensions if needed
      file_path = os.path.join(folder_path, filename)
      try:
        predicted_label, probabilities = predict_audio(file_path, model, label)
        print(f"File: {filename}, Predicted Label: {predicted_label}")
      except Exception as e:
        print(f"Error processing {filename}: {e}")

# Example usage:
test_folder = '/content/Test_submission' # Replace with the actual path to your test folder
predict_audio_folder(test_folder, model, label)